{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Git hub Code on: https://github.com/SpikeStriker/Courses/tree/main/5EL272/saavlabs/Lab1**:\n",
    "\n",
    "\n",
    "One can run the code by spinning up a docker volume using the docker compose file & docker file in the repo. Image Classification\n",
    "\n",
    "Use \"docker compose up\" to start docker and \"docker compose down --rmi all\" to remove all volumnes\n",
    "\n",
    "Results of the exercise found within output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adversarial_Attacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTransforms:\n",
    "    def __init__(self, resize_to):\n",
    "        self.transforms = A.Compose([\n",
    "            A.Resize(resize_to, resize_to),\n",
    "            A.RandomBrightnessContrast(),\n",
    "            A.RandomFog(),\n",
    "            A.RandomRain(),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.transforms(image=np.array(img))['image']\n",
    "    \n",
    "def get_datasets(samples=1000):\n",
    "    dataset = datasets.ImageFolder('files/input/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images', transform=(TrainTransforms(224)))\n",
    "    dataset_size = len(dataset)\n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    dataset_randomised = Subset(dataset, indices[:samples])\n",
    "    return dataset_randomised, dataset.classes\n",
    "\n",
    "def get_data_loaders(dataset_randomised):\n",
    "    train_loader = DataLoader(dataset_randomised, batch_size=128,shuffle=True, num_workers=6)\n",
    "    return train_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_names_df = pd.read_csv('files/input/signnames.csv')\n",
    "class_names = sign_names_df.SignName.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_classes = get_datasets(samples=500)\n",
    "data_loader = get_data_loaders(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in data_loader:\n",
    "    X,y = X.to(device), y.to(device)\n",
    "    break\n",
    "    \n",
    "def plot_images(X,y,yp,M,N):\n",
    "    f,ax = plt.subplots(M,N, sharex=True, sharey=True, figsize=(N*2,M*2))\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            ax[i][j].imshow(1-X[i*N+j][0].cpu().numpy(), cmap=\"gray\")\n",
    "            title = ax[i][j].set_title(\"Pred: {}\".format(class_names[yp[i*N+j].max(dim=0)[1]]))\n",
    "            plt.setp(title, color=('g' if yp[i*N+j].max(dim=0)[1] == y[i*N+j] else 'r'), fontsize=8, wrap=True)\n",
    "            ax[i][j].set_axis_off()\n",
    "    plt.tight_layout(pad=0.04, w_pad=8, h_pad=1.0)\n",
    "    # plt.subplots_adjust(left=1,right=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgClassModel = models.mobilenet_v3_small(pretrained=False)\n",
    "for params in imgClassModel.parameters():\n",
    "    params.requires_grad = False\n",
    "imgClassModel.classifier[3] = nn.Linear(in_features=1024, out_features=43)\n",
    "imgClassModel.to(device)\n",
    "imgClassModel = imgClassModel.eval()\n",
    "imgClassModel.load_state_dict(torch.load('files/outputs/model.pth', map_location=device)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = imgClassModel(X)\n",
    "plot_images(X, y, yp, 3, 6)\n",
    "print(\"Accuracy of model predictions over a training sample of 500 images: {}\".format(sum(yp.max(dim=1)[1] == y)/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Untargeted attack using Fast Gradient Sign Method (FGSM), using the function fgsm().**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Images 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(model, X, y, epsilon):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
    "    loss.backward()\n",
    "    return epsilon * delta.grad.detach().sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = fgsm(imgClassModel, X, y, 0.1)\n",
    "yp = imgClassModel(X + delta)\n",
    "plot_images(X+delta, y, yp, 3, 6)\n",
    "print(\"Accuracy of model predictions: {}\".format(sum(yp.max(dim=1)[1] == y)/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Untargeted attack using Projected Gradient Descent, using the function pgd_linf() (You may use the Projected Steepest Descent variant to accelerate the process).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Images 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(model, X, y, epsilon, alpha, num_iter):\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    for t in range(num_iter):\n",
    "        loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
    "        loss.backward()\n",
    "        delta.data = (delta + X.shape[0]*alpha*delta.grad.data).clamp(-epsilon,epsilon)\n",
    "        delta.grad.zero_()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pgd(imgClassModel, X, y, 0.1, 1e4, 1000)\n",
    "yp = imgClassModel(X + delta)\n",
    "plot_images(X+delta, y, yp, 3, 6)\n",
    "print(\"Accuracy of model predictions: {}\".format(sum(yp.max(dim=1)[1] == y)/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Targeted attack using Projected Gradient Descent, using the function pgd_linf_targ(), which aims to maximize logit of the target class y_targ and minimize logit of the true class y. You may choose any target class, but I suggest using \"Speed Limit\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target = Speed limit (100km/h)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Images 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_linf_targ(model, X, y, epsilon, alpha, num_iter, y_targ):\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    for t in range(num_iter):\n",
    "        yp = model(X + delta)\n",
    "        loss = (yp[:,y_targ] - yp.gather(1,y[:,None])[:,0]).sum()\n",
    "        loss.backward()\n",
    "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
    "        delta.grad.zero_()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pgd_linf_targ(imgClassModel, X, y, epsilon=0.2, alpha=1e-2, num_iter=400, y_targ=7)\n",
    "yp = imgClassModel(X + delta)\n",
    "plot_images(X+delta, y, yp, 3, 6)\n",
    "print(\"Accuracy of model predictions: {}\".format(sum(yp.max(dim=1)[1] == y)/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Targeted attack using Projected Gradient Descent, using the function pgd_linf_targ2(),  which  aims to maximize logit of the target class y_targ and minimize logit of all the other classes y'.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target = Speed limit (100km/h)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Images 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_linf_targ2(model, X, y, epsilon, alpha, num_iter, y_targ):\n",
    "    \"\"\" Construct targeted adversarial examples on the examples X\"\"\"\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    for t in range(num_iter):\n",
    "        yp = model(X + delta)\n",
    "        loss = 2*yp[:,y_targ].sum() - yp.sum()\n",
    "        loss.backward()\n",
    "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
    "        delta.grad.zero_()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pgd_linf_targ2(imgClassModel, X, y, epsilon=0.2, alpha=1e-2, num_iter=400, y_targ=7)\n",
    "yp = imgClassModel(X + delta)\n",
    "plot_images(X+delta, y, yp, 3, 6)\n",
    "print(\"Accuracy of model predictions: {}\".format(sum(yp.max(dim=1)[1] == y)/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
